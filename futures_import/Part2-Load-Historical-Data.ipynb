{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.quantrocket.com\"><img alt=\"QuantRocket logo\" src=\"https://www.quantrocket.com/assets/img/notebook-header-logo.png\"></a><br>\n",
    "<a href=\"https://www.quantrocket.com/disclaimer/\">Disclaimer</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "[Import Futures](Introduction.ipynb) â€º Part 2: Load Historical Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Historical Data\n",
    "\n",
    "Now that the securities master database contains records for the historical contracts, we can import historical futures data using the general guidelines outlined in the [Custom Data](https://www.quantrocket.com/docs/#custom-data) section of the Usage Guide. If you haven't read that section, it is recommended to do so now.\n",
    "\n",
    "Depending on the volume of data you are importing, you may need to import the data into multiple smaller databases instead of one large one. For best performance, try to limit each database to a few GB of data. If you are importing end-of-day data, creating one database per exchange is likely appropriate. If you are importing intraday data, one database per root symbol (or per small group of root symbols) is more appropriate.  \n",
    "\n",
    "This notebook loads end-of-day simulated sample data for ES as an example but is designed to make it easy to modify the code for more complicated scenarios. The example data is in [CME_sample_data.csv](historical_data/CME_sample_data.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom database\n",
    "\n",
    "First, we create a custom database for the historical data. To facilitate ingestion into a Zipline bundle later, the database column names should be `Open`, `High`, `Low`, `Close`, and `Volume`. The field names in the sample CSV are different from this (they are all lowercase), but we will rename them later. Additional columns (like `OpenInterest` in this example) are optional depending on what's in your source data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'successfully created quantrocket.v2.history.imported-futures-1d.sqlite'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.history import create_custom_db\n",
    "\n",
    "DB_NAME = \"imported-futures-1d\" # store for later in notebook\n",
    "\n",
    "create_custom_db(DB_NAME, bar_size=\"1d\", columns={\n",
    "    \"Open\": \"float\",\n",
    "    \"High\": \"float\",\n",
    "    \"Low\": \"float\",\n",
    "    \"Close\": \"float\",\n",
    "    \"Volume\": \"int\",\n",
    "    \"OpenInterest\": \"int\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Historical Futures Data\n",
    "\n",
    "Next, upload your historical futures data into the `historical_data` subdirectory of this directory. This can be done through the JupyterLab interface for small amounts of data, or you can use `docker cp` from your host machine as shown below:\n",
    "\n",
    "```\n",
    "$ docker cp host/path/to/historical_data/. quantrocket-jupyter-1:/codeload/futures_import/historical_data/\n",
    "```\n",
    "\n",
    "See the [Usage Guide](https://www.quantrocket.com/docs/#custom-data-collect-custom-data) for additional notes about `docker cp`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Symbols to Sids\n",
    "\n",
    "Next, we need to map the symbols in your historical data to QuantRocket SIDs. This is typically the most cumbersome step in the import process, and the exact steps will vary depending on the format of your data. \n",
    "\n",
    "The goal of this step is to generate a Python dictionary mapping symbols in the source data to QuantRocket SIDs. In a subsequent step, we will use this dictionary to append sids to the historical source data as we import it into the custom database created above.\n",
    "\n",
    "If you have a master list of individual contract specifications from your data provider, you can use it to create the mapping. In this example, we don't have a master list and will extract the futures symbols from the price data files.\n",
    "\n",
    "First, we initialize the mapping dictionary. The keys will be tuples of (MIC, symbol) and the values will be sids. Once we've populated the dictionary, it will look something like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    ('XCME', 'ESU08'): 'QF000000654947', \n",
    "    ('XCME', 'ESZ08'): 'QF000000654948',\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of (MIC, symbol): sid\n",
    "mic_and_symbol_to_sid = {\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we interactively match the symbols in the source data to contracts in the securities master database.\n",
    "\n",
    "Two utility files will help with the mapping process. The [`codeload.futures_import.utils`](utils.py) module provides a `MONTH_CODES_TO_MONTH_NUMS` dictionary that maps futures month codes to the corresponding month nums, for example U is mapped to 9 (September). The [exchanges_to_mics.yml](contract_chains/exchanges_to_mics.yml) YAML file contains a dictionary mapping common exchange codes to the corresponding MIC (for example, NYMEX -> XNYM). If any of the exchange codes used by your data provider are not in this YAML file, you should add them. (The `DataMapper` class, below, will raise an exception to remind you if this is the case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeload.futures_import.utils import MONTH_CODES_TO_MONTH_NUMS\n",
    "import yaml\n",
    "\n",
    "with open(\"contract_chains/exchanges_to_mics.yml\") as f:\n",
    "    EXCHANGES_TO_MICS = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `DataMapper` class can be used as a template for performing the interactive mapping. You would need to modify this class based on the format of your data.\n",
    "\n",
    "A description of the class's methods follows:\n",
    "\n",
    "**`run()`**\n",
    "\n",
    "This is the main entry point. It does the following:\n",
    "* calls `load_source_files()`, which returns a tuple of the MIC and DataFrame contents of each source file\n",
    "* calls `load_contracts_for_mic()`, which loads contracts from the securities master database for the current MIC\n",
    "* iterates through the unique symbols in the source data and calls `map_symbol()` for each. The `map_symbol()` method chooses the matching contract from the securities master database and associates its SID with the symbol.\n",
    "\n",
    "You may not need to modify this method.\n",
    "\n",
    "**`load_source_files()`**\n",
    "\n",
    "This method iterates through the source files, and for each one, returns the MIC and the DataFrame content from the source file. In this example, the exchange is extracted from the filename and the corresponding MIC is looked up in `EXCHANGES_TO_MICS`. You will likely need to modify this method to conform to your source data.\n",
    "\n",
    "**`load_contracts_for_mic()`**\n",
    "\n",
    "This methods load contracts from the securities master database for the specified MIC. You shouldn't need to modify this method.\n",
    "\n",
    "**`map_symbol()`**\n",
    "\n",
    "This method parses the symbol into a root symbol and contract month and selects the corresponding record from the contracts DataFrame that was loaded from the securities master database. You will likely need to modify this method to conform to your source data.\n",
    "\n",
    "### Potential Gotchas\n",
    "\n",
    "Note the following potential gotchas when importing futures data:\n",
    "\n",
    "* For some contracts, such as Crude Oil (CL), the last trade date (`ibkr_LastTradeDate`) occurs in the month preceding the contract month (`ibkr_ContractMonth`). Be aware of this when choosing which field to match on. When the contract symbol includes a month code and year (e.g. `ESU08`), this generally should be matched to `ibkr_ContractMonth`, not the month and year of `ibkr_LastTradeDate`. This is what the `DataMapper` class does.\n",
    "* `ibkr_Symbol` is the root symbol as stored in IBKR's system, which sometimes differs from the root symbol used by the exchange. The root symbol as used by the exchange can be found in the `ibkr_TradingClass` field. For this reason, it's generally better to match on `ibkr_TradingClass` rather than `ibkr_Symbol`. This is what the `DataMapper` class does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from quantrocket.master import get_securities\n",
    "\n",
    "# If a root symbol in the source file doesn't match the ibkr_TradingClass in\n",
    "# the securities master database, you can manually add the mapping here\n",
    "ROOT_SYMBOL_TO_IBKR_TRADING_CLASS = {\n",
    "    # data file root symbol: securities master ibkr_TradingClass\n",
    "    # for example:\n",
    "    # \"E6\": \"6E\",\n",
    "}\n",
    "\n",
    "SYMBOL_FIELDNAME = \"symbol\" # the name of the field in the CSV files that contains the symbol\n",
    "\n",
    "class DataMapper:\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        This is the main method that calls all the other methods.\n",
    "        \"\"\"\n",
    "\n",
    "        for mic, data in self.load_source_files():\n",
    "\n",
    "            contracts = self.load_contracts_for_mic(mic)\n",
    "\n",
    "            symbols = data[SYMBOL_FIELDNAME].unique()\n",
    "\n",
    "            for symbol in symbols:\n",
    "\n",
    "                # Skip if already mapped\n",
    "                if (mic, symbol) in mic_and_symbol_to_sid:\n",
    "                    continue\n",
    "\n",
    "                self.map_symbol(mic, symbol, contracts)\n",
    "\n",
    "    def load_source_files(self):\n",
    "        \"\"\"\n",
    "        Load source files and return a generator of tuples of\n",
    "        the form (mic, data).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of str and DataFrame\n",
    "            The MIC and DataFrame content of each source file.\n",
    "        \"\"\"\n",
    "        # Get a list of all CSV files in the historical_data directory\n",
    "        filepaths = glob.glob(\"historical_data/*.csv\")\n",
    "\n",
    "        for filepath in filepaths:\n",
    "\n",
    "            filename = os.path.basename(filepath)\n",
    "\n",
    "            # In the example files, the exchange is the first part of\n",
    "            # the filename; extract it\n",
    "            exchange = filename.split(\"_\")[0]\n",
    "\n",
    "            if exchange not in EXCHANGES_TO_MICS:\n",
    "                raise ValueError(\n",
    "                    f\"Exchange {exchange} not found in EXCHANGES_TO_MICS, please add it\")\n",
    "\n",
    "            mic = EXCHANGES_TO_MICS[exchange]\n",
    "\n",
    "            # Load the CSV file into a DataFrame\n",
    "            data = pd.read_csv(filepath)\n",
    "\n",
    "            yield mic, data\n",
    "\n",
    "    def load_contracts_for_mic(self, mic):\n",
    "        \"\"\"\n",
    "        Return a DataFrame of contracts from the securities master database\n",
    "        for the specified MIC.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mic : str\n",
    "            The MIC to load contracts for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            The contracts.\n",
    "        \"\"\"\n",
    "        contracts = get_securities(\n",
    "            exchanges=mic,\n",
    "            sec_types=\"FUT\",\n",
    "            fields=[\n",
    "                \"ibkr_LocalSymbol\", # e.g. ESU8 or ESU08 (year may be 1 digit or 2 digits)\n",
    "                \"ibkr_TradingClass\", # e.g. ES\n",
    "                \"ibkr_ContractMonth\", # e.g. 200809\n",
    "                \"ibkr_LastTradeDate\", # e.g. 2008-09-16\n",
    "                \"ibkr_LongName\", # e.g. E-mini S&P 500\n",
    "            ]\n",
    "        ).sort_values(\"ibkr_LastTradeDate\")\n",
    "        return contracts\n",
    "\n",
    "    def map_symbol(self, mic, symbol, contracts):\n",
    "        \"\"\"\n",
    "        Map the symbol from the source files to the QuantRocket SID and\n",
    "        store the mapping in the mic_and_symbol_to_sid dictionary. Obtain\n",
    "        user confirmation of the mapping.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mic : str\n",
    "            The MIC of the symbol.\n",
    "\n",
    "        symbol : str\n",
    "            The symbol from the source file. E.g. ESU08.\n",
    "\n",
    "        contracts : DataFrame\n",
    "            The contracts from the securities master database for this MIC.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Extract the root symbol from contract symbol (= everything but\n",
    "        # last 3 characters)\n",
    "        root_symbol = symbol[:-3]\n",
    "\n",
    "        # respect manual mappings\n",
    "        if root_symbol in ROOT_SYMBOL_TO_IBKR_TRADING_CLASS:\n",
    "            root_symbol = ROOT_SYMBOL_TO_IBKR_TRADING_CLASS[root_symbol]\n",
    "\n",
    "        # Extract the month code from the contract symbol (= 3rd to last\n",
    "        # character)\n",
    "        month_code = symbol[-3]\n",
    "        # look up month num from month code\n",
    "        month_num = MONTH_CODES_TO_MONTH_NUMS[month_code]\n",
    "        # pad month_num: 1 -> 01\n",
    "        month = str(month_num).zfill(2)\n",
    "\n",
    "        # Extract the 2-digit year from the contract symbol (= last 2\n",
    "        # characters)\n",
    "        two_digit_year = symbol[-2:]\n",
    "        # prefix two_digit_year with century 19 or 20\n",
    "        if int(two_digit_year) < 50:\n",
    "            year = \"20\" + two_digit_year\n",
    "        else:\n",
    "            year = \"19\" + two_digit_year\n",
    "\n",
    "        contract_month = int(year + month)\n",
    "\n",
    "        # Match on root symbol and contract month\n",
    "        matching_contracts = contracts[\n",
    "            (contracts.ibkr_TradingClass == root_symbol)\n",
    "            &\n",
    "            (contracts.ibkr_ContractMonth == contract_month)\n",
    "        ]\n",
    "\n",
    "        if matching_contracts.empty:\n",
    "            raise ValueError(\n",
    "                f\"No matching contracts found for {mic} symbol {symbol}, you can run \"\n",
    "                f\"DataMapper().load_contracts_for_mic('{mic}') to see the available contracts \"\n",
    "                \"for this mic\")\n",
    "\n",
    "        # if there is exactly one match, show it and ask for confirmation\n",
    "        if len(matching_contracts) == 1:\n",
    "            match = matching_contracts.reset_index().iloc[0]\n",
    "            print(f\"found 1 matching sid for {mic} symbol {symbol}\\n\")\n",
    "            print(match.to_string())\n",
    "            answer = input(f\"assign this sid to this symbol? y/n\")\n",
    "            if answer != \"y\":\n",
    "                raise KeyboardInterrupt(\"You entered something other than y\")\n",
    "            sid = match.Sid\n",
    "\n",
    "        # if there are multiple matches, show them and ask user to select\n",
    "        else:\n",
    "            print(f\"found {len(matching_contracts)} matching sids for {mic} symbol {symbol}\\n\")\n",
    "            print(matching_contracts.to_string())\n",
    "            sid = input(f\"enter the sid to assign to this symbol\")\n",
    "            if sid not in matching_contracts.index:\n",
    "                raise KeyboardInterrupt(f\"{sid} is not one of the matching sids\")\n",
    "\n",
    "        mic_and_symbol_to_sid[(mic, symbol)] = sid\n",
    "\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataMapper` class can now be run. Since the class doesn't modify any files or databases but simply populates the `mic_and_symbol_to_sid` dictionary, it is safe to run the class over and over while working through issues. The `run()` method will skip any symbols that you have already mapped. To completely start over, re-run the cell that instantiates the `mic_and_symbol_to_sid` dictionary to clear its contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataMapper().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mic_and_symbol_to_sid` dictionary should now be populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('XCME', 'ESU08'): 'QF000000654947', ('XCME', 'ESZ08'): 'QF000000654948'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_and_symbol_to_sid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into Custom Database\n",
    "\n",
    "Now that we have created the mapping of symbols to SIDs, we are ready to load the data into the database.\n",
    "\n",
    "The following `DataLoader` class provides a template for performing the loading.\n",
    "\n",
    "A description of the class's methods follows:\n",
    "\n",
    "**`run()`**\n",
    "\n",
    "This is the main entry point. It does the following:\n",
    "* calls `load_source_files()`, which returns the MIC and the DataFrame contents from each source file. (`DataLoader` inherits from `DataMapper` to be able to re-use this method from the parent class.)\n",
    "* adds a `Sid` column to the DataFrame and assigns the correct SID for each symbol, as defined in the `mic_and_symbol_to_sid` dictionary from earlier.\n",
    "* further prepares the DataFrame by renaming columns, parsing the date column, and dropping unneeded columns\n",
    "* inserts the DataFrame into the database\n",
    "\n",
    "You may not need to modify this method.\n",
    "  \n",
    "**`prepare_data()`**\n",
    "\n",
    "This method renames source columns to match the expected column names in the custom database, parses the date column, and drops unneeded columns. You will likely need to modify this method to conform to your source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantrocket.db import connect_sqlite, insert_or_replace, list_databases\n",
    "\n",
    "# look up the custom database path and open a SQLite connection to it\n",
    "db_path = list_databases(\n",
    "    services=\"history\",\n",
    "    codes=DB_NAME,\n",
    "    detail=True)[\"sqlite\"][0][\"path\"]\n",
    "\n",
    "db_conn = connect_sqlite(db_path)\n",
    "\n",
    "class DataLoader(DataMapper):\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Load each source file, append the sids from mic_and_symbol_to_sid,\n",
    "        and insert the data into the custom database.\n",
    "        \"\"\"\n",
    "        for mic, data in self.load_source_files():\n",
    "\n",
    "            symbols = data[SYMBOL_FIELDNAME].unique()\n",
    "            data[\"Sid\"] = None\n",
    "\n",
    "            for symbol in symbols:\n",
    "                # lookup sid for symbol and set it in DataFrame\n",
    "                sid = mic_and_symbol_to_sid[(mic, symbol)]\n",
    "                data.loc[data[SYMBOL_FIELDNAME] == symbol, \"Sid\"] = sid\n",
    "\n",
    "            # further data prep\n",
    "            data = self.prepare_data(data)\n",
    "\n",
    "            # get user confirmation that everything looks okay\n",
    "            print(data.head().to_string())\n",
    "            answer = input(f\"look okay to insert {len(data)} records? y/n\")\n",
    "            if answer != \"y\":\n",
    "                raise KeyboardInterrupt(\"You entered something other than y\")\n",
    "\n",
    "            insert_or_replace(data, \"Price\", db_conn)\n",
    "\n",
    "            clear_output()\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        \"\"\"\n",
    "        Perform data prep as discussed in the 'Prepare custom data' section of the\n",
    "        usage guide: https://www.quantrocket.com/docs/#custom-data-prepare-custom-data\n",
    "\n",
    "        Specifically:\n",
    "\n",
    "        - rename columns\n",
    "        - parse date column\n",
    "        - drop extraneous columns\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : DataFrame\n",
    "            The data to prepare.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            The prepared data.\n",
    "        \"\"\"\n",
    "\n",
    "        # rename columns\n",
    "        data = data.rename(columns={\n",
    "            # source file column name: custom database column name\n",
    "            \"date\": \"Date\",\n",
    "            \"open\": \"Open\",\n",
    "            \"high\": \"High\",\n",
    "            \"low\": \"Low\",\n",
    "            \"close\": \"Close\",\n",
    "            \"volume\": \"Volume\",\n",
    "            \"open_interest\": \"OpenInterest\",\n",
    "        })\n",
    "\n",
    "        # parse date column (if intraday, include a timezone as shown in the\n",
    "        # usage guide)\n",
    "        data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "\n",
    "        # the symbol column is no longer needed\n",
    "        data = data.drop(SYMBOL_FIELDNAME, axis=1)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the `DataLoader` and insert the data into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Open     High      Low    Close   Volume  OpenInterest             Sid\n",
      "0 2008-09-18  1163.75  1213.25  1133.00  1198.25  6013113       2380251  QF000000654947\n",
      "1 2008-09-17  1215.50  1227.75  1154.50  1160.75  5915836       3490395  QF000000654947\n",
      "2 2008-09-16  1196.75  1219.00  1161.75  1214.25  6078506       3205598  QF000000654947\n",
      "3 2008-09-15  1230.25  1237.75  1194.50  1195.00  5191192       3050694  QF000000654947\n",
      "4 2008-09-12  1251.00  1257.75  1233.50  1257.25  3648404       2809352  QF000000654947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look okay to insert 627 records? y/n y\n"
     ]
    }
   ],
   "source": [
    "DataLoader().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## *Next Up*\n",
    "\n",
    "Part 3: [Interactive Brokers Data Collection](Part3-IBKR-Data-Collection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
